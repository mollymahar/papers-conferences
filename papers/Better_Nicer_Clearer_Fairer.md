# Better, Nicer, Clearer, Fairer: A Critical Assessment of the Movement for Ethical Artificial Intelligence and Machine Learning

Main idea: this paper does a close reading of the "Ethical AI" statements that have been promulgated by large tech companies and organizations recently to pull out their assumptions and how they've captured and framed the conversation. (Super interesting for someone who loves focusing on what people don't say!)

The paper finds **seven core themes**:
1. **universal concerns, objectively measured**
	- positive and negative aspects of AI are of universal concern
	- we all share a common language of ethical concern
	- the concerns can be addressed by measuring the impacts
2. **expert oversight**
	- these statements don't try to mass mobilizeâ€”-they "draw a narrow circle of who can or should adjudicate ethical concerns around AI/ML"
	- experts are primarily technical, secondarily legal
	- mindset of "Experts make AI happen, Other Stakeholders have AI happen to them"
	- some statements do include/acknowledge importance of non-technical expertise, so this theme is not across-the-board
3. **values-driven determinism**
	- statements are offered as technological determinism: that humans must adapt to AI, and that AI will take our jobs. Yet we are also responsible.
	- this limits the debate to design and implementation, rather than the question of whether we should build ANY of these systems in the first place
	- the possibility of _not_ building something is rarely/never offered as an option
4. **design as the locus of ethical scrutiny**
	- business decisions are not subjected to the same ethical scrutiny as design decisions. "In this way, the vision statements are reminiscent of many professional codes of ethics, which often detail the responsibilities of individual professionals without actively scrutinizing the nature of the profession or business in question."
5. **better building**
	- because any critical discussion of business practices is effectively off the table in these statements, "building better" is the only path forward
	- no statement offers the option of not building something
6. **stakeholder-driven legitimacy**
	- proponents support engaging as many expert stakeholders as possible
	- having these expert stakeholders vet design decisions hints at transparency but actually offers no accountability or commitment
	- legitimacy appears to hold even if the expert stakeholders have zero capacity to influence or change designs in consideration
7. **machine translation**
	- explainable and transparent AI are positioned as both a foundation of moral/ethical AI and also a means to getting there
	- suggestions of public accountability via an obligation to report/explain/justify decision-making by AI systems

Also brings up an interesting point about "how ethics and ethical codes designate and defend social status and expertise more than enforce consistent moral or societal virtues."

Overall, these discussions and statements seem to be positioned mainly for public perception, with problems framed as mainly technical rather than democratic or subject to democratic interventions.

I love one of the closing statements: 
> They also take for granted the non-obvious assumption that poor ethics and bad designs produce harmful outcomes. Other causation narratives about the chaos of new, intelligent tools interacting in the wild, or large corporations dominating political processes with no democratic accountability, are equally plausible.
